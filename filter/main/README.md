# Confluence Page Analysis Pipeline

Complete workflow for analyzing Confluence pages, converting HTML to Markdown, and detecting gibberish content.

---

## ğŸ“‹ Pipeline Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    CONFLUENCE HTML INPUT                        â”‚
â”‚                 (confluence_markdown.jsonl)                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STEP 1: HTML to Markdown Conversion                            â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                           â”‚
â”‚  File: conversion3.py                                           â”‚
â”‚  Function: convert_html_to_markdown()                           â”‚
â”‚                                                                 â”‚
â”‚  Input:  HTML string from Confluence body field                 â”‚
â”‚  Output: Clean Markdown text                                    â”‚
â”‚  â€¢ Handles tables, lists, macros, code blocks                   â”‚
â”‚  â€¢ Preserves user mentions and attachments                      â”‚
â”‚  â€¢ Converts Confluence-specific elements                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STEP 2: Document Analysis                                      â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                      â”‚
â”‚  File: check_markdown.py                                        â”‚
â”‚  Functions:                                                     â”‚
â”‚  â€¢ extract_tables_from_markdown() - Extract tables              â”‚
â”‚  â€¢ analyze_table_content() - Analyze each table                 â”‚
â”‚  â€¢ analyze_markdown_structure() - Analyze document              â”‚
â”‚  â€¢ summarize_document() - Generate summary                      â”‚
â”‚                                                                 â”‚
â”‚  Output:                                                        â”‚
â”‚  â€¢ Table metrics (words, links, images, mentions)               â”‚
â”‚  â€¢ Document structure (headings, paragraphs, lists)             â”‚
â”‚  â€¢ Content statistics (excluding headings/tables)               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STEP 3: Data Collection                                        â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                        â”‚
â”‚  File: collect.py                                               â”‚
â”‚  Function: collect_document_data()                              â”‚
â”‚                                                                 â”‚
â”‚  Aggregates all analysis data into single dictionary:           â”‚
â”‚  â€¢ Document metadata (id, title, url)                           â”‚
â”‚  â€¢ Table data with analysis                                     â”‚
â”‚  â€¢ Word counts (total, excluding tables)                        â”‚
â”‚  â€¢ Links, images, files, mentions counts                        â”‚
â”‚  â€¢ Structure summary                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STEP 4: Gibberish Detection                                    â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                   â”‚
â”‚  Files: table_decider.py + page_decider.py                      â”‚
â”‚                                                                 â”‚
â”‚  4a. Table-Level Decision (table_decider.py)                    â”‚
â”‚      â€¢ Checks meaningful words (â‰¥3)                             â”‚
â”‚      â€¢ Checks for links, images, files, mentions                â”‚
â”‚      â€¢ Returns: is_gibberish (bool) + reason                    â”‚
â”‚                                                                 â”‚
â”‚  4b. Page-Level Decision (page_decider.py)                      â”‚
â”‚      â€¢ Checks for useful tables                                 â”‚
â”‚      â€¢ Checks words outside tables (â‰¥20)                        â”‚
â”‚      â€¢ Checks content outside tables                            â”‚
â”‚      â€¢ Returns: is_gibberish (bool) + decision_info             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STEP 5: Output & Evaluation                                    â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                    â”‚
â”‚  â€¢ decider.py - Test individual pages                           â”‚
â”‚  â€¢ decider_label_studio.py - Batch process with async           â”‚
â”‚  â€¢ metrics.py - Calculate accuracy, precision, recall           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Confluence HTML â†’ Markdown â†’ Analysis â†’ Detection â†’ Metrics
     â†“              â†“           â†“          â†“          â†“
conversion3.py  check_markdown  collect  page_decider  metrics.py
```

**Flow:** HTML â†’ Markdown â†’ Analysis â†’ Detection â†’ Evaluation

---

## ğŸ“¦ Modules

### 1ï¸âƒ£ conversion3.py
**Convert Confluence HTML to Markdown**

#### What it does
Converts Confluence Storage Format (XHTML) into clean Markdown text, handling:
- Tables (colspan/rowspan expansion)
- Confluence macros (code, expand, status, jira)
- User mentions `[~username]`
- Images and attachments
- Nested lists and structures
- Date formatting in table cells

#### How it works
1. Parses HTML with BeautifulSoup
2. Recursively converts nodes to Markdown
3. Handles special Confluence elements
4. Cleans and normalizes whitespace

#### Configuration
```python
DEFAULT_CONFLUENCE_DATA_PATH = "/path/to/confluence_markdown.jsonl"
DEFAULT_TEST_INDEX = 6687
```

#### How to run
```bash
python conversion3.py
```

#### When to use
- Test HTML to Markdown conversion on a specific record
- Debug conversion issues
- Validate Markdown output quality

---

### 2ï¸âƒ£ check_markdown.py
**Analyze Markdown documents**

#### What it does
Analyzes converted Markdown to extract structured information:
- Tables (content, dimensions, fill percentage)
- Document structure (headings, paragraphs, lists)
- Content metrics (words, links, images, mentions)
- Separate counts for content inside/outside tables

#### How it works
1. Converts HTML to Markdown (calls `conversion3.py`)
2. Extracts tables using regex patterns
3. Analyzes table content (words, links, images)
4. Analyzes document structure
5. Generates summary statistics

#### Key functions
- `extract_tables_from_markdown()` - Extracts all tables
- `analyze_table_content()` - Analyzes individual tables
- `analyze_markdown_structure()` - Analyzes document structure
- `summarize_document()` - Generates complete summary

#### Configuration
```python
DEFAULT_DATA_FILE = "/path/to/confluence_markdown.jsonl"
DEFAULT_TEST_INDEX = 100
```

#### How to run
```bash
python check_markdown.py
```

#### When to use
- Understand document structure
- Verify table extraction accuracy
- Debug analysis logic
- Inspect content metrics

---

### 3ï¸âƒ£ collect.py
**Aggregate analysis data**

#### What it does
Collects all document analysis data into a unified dictionary:
- Document metadata (id, title, url)
- All tables with individual analysis
- Word counts (total, in tables, outside tables)
- Content counts (links, images, files, mentions)
- Useful vs gibberish table classification

#### How it works
1. Takes a document as input
2. Calls `check_markdown.py` for analysis
3. Processes each table with `table_decider.py`
4. Aggregates metrics into single dictionary
5. Returns comprehensive data structure

#### Output structure
```python
{
    "id": "page_id",
    "title": "Page Title",
    "url": "page_url",
    "num_tables": 3,
    "tables": [...],
    "table_word_count": 150,
    "total_word_count": 250,
    "word_count_excluding_tables": 100,
    "useful_table_count": 2,
    "gibberish_table_count": 1,
    # ... more fields
}
```

#### Configuration
```python
DEFAULT_DATA_FILE = "/path/to/confluence_markdown.jsonl"
DEFAULT_TEST_INDEX = 2000
```

#### How to run
```bash
python collect.py
```

#### When to use
- Test data collection pipeline
- Verify aggregated metrics
- Debug metric calculations
- Inspect complete document data

---

### 4ï¸âƒ£ table_decider.py
**Detect gibberish tables**

#### What it does
Determines if a table contains useful information or is gibberish.

#### Decision logic
A table is **USEFUL** if it has ANY of:
- â‰¥3 meaningful words (excludes: draft, tbd, yes, no, empty cells)
- Any links
- Any images
- Any file references
- Any user mentions

Otherwise, it's **GIBBERISH**.

#### How it works
1. Receives table analysis from `collect.py`
2. Counts meaningful words (excludes placeholders)
3. Checks for links, images, files, mentions
4. Returns decision + reason

#### Configuration
```python
DEFAULT_DATA_FILE = "/path/to/confluence_markdown.jsonl"
DEFAULT_TEST_INDEX = 150
MEANINGFUL_WORDS_THRESHOLD = 3
```

#### How to run
```bash
python table_decider.py
```

#### When to use
- Test table classification logic
- Adjust meaningful word threshold
- Debug false positives/negatives
- Understand table decisions

**Example output:**
```
Table 0 is âœ… Useful
  Decision: Useful: 15 meaningful words (excl. headings & placeholders)
  Metrics:
    â€¢ Meaningful Words: 15
    â€¢ Links: 2
    â€¢ Images: 0
```

---

### 5ï¸âƒ£ page_decider.py
**Detect gibberish pages**

#### What it does
Determines if an entire Confluence page contains useful information or is gibberish.

#### Decision logic
A page is **USEFUL** if it has ANY of:
- â‰¥1 useful table (from `table_decider.py`)
- â‰¥20 words outside tables (excluding headings)
- Any links outside tables
- Any images outside tables
- Any file references outside tables
- Any user mentions outside tables

Otherwise, it's **GIBBERISH**.

#### How it works
1. Receives document data from `collect.py`
2. Checks for useful tables
3. Checks content outside tables
4. Returns decision + detailed info

#### Configuration
```python
DEFAULT_DATA_FILE = "/path/to/confluence_markdown.jsonl"
DEFAULT_TEST_INDEX = 100
WORDS_OUTSIDE_TABLES_THRESHOLD = 20
```

#### How to run
```bash
# Use default test index
python page_decider.py

# Test specific index
python page_decider.py 250
```

#### When to use
- Test page-level classification
- Adjust threshold parameters
- Debug false positives/negatives
- Analyze specific pages

**Example output:**
```
================================================================================
ğŸ“„ PAGE ANALYSIS - Page 100
================================================================================
URL: https://confluence.example.com/page/123
Title: Project Documentation

âœ… USEFUL PAGE
Decision: Useful: 1 useful table(s), 45 words outside tables

Page Metrics:
  ğŸ“Š Tables:
    â€¢ Total: 2
    â€¢ Useful: 1
    â€¢ Gibberish: 1
  ğŸ“ Content Outside Tables:
    â€¢ Words: 45
    â€¢ Links: 3
    â€¢ Images: 1
```

---

### 6ï¸âƒ£ decider.py
**Test specific page by ID and URL**

#### What it does
Quick test script for analyzing a specific Confluence page by its ID and URL.

#### How it works
1. Loads all documents
2. Finds page by ID and URL
3. Runs complete analysis pipeline
4. Displays results

#### Configuration
```python
DEFAULT_DATA_FILE = "/path/to/confluence_markdown.jsonl"
DEFAULT_PAGE_ID = 2635071834
DEFAULT_URL = "https://confluence.example.com/pages/..."
```

#### How to run
```bash
python decider.py
```

#### When to use
- Test a specific known page
- Debug particular page issues
- Validate pipeline on real examples

---

### 7ï¸âƒ£ decider_label_studio.py
**Batch process annotated data**

#### What it does
Processes all Label Studio annotated pages asynchronously and generates predictions.

#### How it works
1. Loads annotated data from Label Studio export
2. Processes each document through pipeline
3. Runs gibberish detection
4. Saves results with predictions
5. Uses async processing for speed

#### Features
- Async batch processing (10 documents at a time)
- Progress bars with tqdm
- Error handling per document
- JSONL output format

#### Configuration
```python
DEFAULT_INPUT_FILE = "/path/to/label_studio_combined_processed.jsonl"
DEFAULT_OUTPUT_FILE = "/path/to/label_studio_gibberish_results.jsonl"
DEFAULT_BATCH_SIZE = 10
```

#### How to run
```bash
python decider_label_studio.py
```

#### When to use
- Process all annotated pages
- Generate predictions for evaluation
- Run production pipeline on dataset
- Compare model vs human annotations

**Output format:**
```json
{
    "id": "page_id",
    "title": "Page Title",
    "url": "page_url",
    "annotation": "yes",
    "result": {
        "is_gibberish": "yes",
        "reason": "Gibberish: No useful tables, only 5 words outside tables"
    }
}
```

---

### 8ï¸âƒ£ metrics.py
**Calculate model performance**

#### What it does
Evaluates model predictions against human annotations and calculates metrics.

#### Metrics calculated
- **Accuracy** - Overall correctness
- **Precision** - Gibberish prediction accuracy
- **Recall** - Gibberish detection rate
- **F1-Score** - Balanced performance
- **Confusion Matrix** - Detailed breakdown
- **Classification Report** - Per-class metrics

#### How it works
1. Loads results from `decider_label_studio.py`
2. Extracts ground truth (annotations) and predictions
3. Calculates all metrics using scikit-learn
4. Displays formatted results

#### Configuration
```python
DEFAULT_INPUT_FILE = "/path/to/label_studio_gibberish_results.jsonl"
```

#### How to run
```bash
python metrics.py
```

#### When to use
- Evaluate model performance
- Compare different approaches
- Measure impact of threshold changes
- Generate performance reports

**Example output:**
```
Overall Accuracy: 84.2%

Precision:
  â€¢ Gibberish: 88.5%
  â€¢ Useful: 78.3%

Recall:
  â€¢ Gibberish: 91.2%
  â€¢ Useful: 72.1%

Confusion Matrix:
              Predicted
              Yes    No
Actual  Yes   365    33
        No     48    168
```

---

## ğŸ”§ Configuration Guide

All scripts have configuration at the top:

```python
# =============================================================================
#                           CONFIGURATION PARAMETERS
# =============================================================================

# Data path
DEFAULT_DATA_FILE = "/Users/rishabh.singh/Desktop/markdown_filter/filter/data/confluence_markdown.jsonl"

# Test indices
DEFAULT_TEST_INDEX = 100

# Thresholds
MEANINGFUL_WORDS_THRESHOLD = 3        # table_decider.py
WORDS_OUTSIDE_TABLES_THRESHOLD = 20   # page_decider.py

# Processing
DEFAULT_BATCH_SIZE = 10               # decider_label_studio.py
```

**To modify:**
1. Open the Python file
2. Edit values in CONFIGURATION PARAMETERS section
3. Save and run

---

## ğŸš€ Common Workflows

### Workflow 1: Test single page
```bash
# By index
python page_decider.py 100

# By ID and URL
python decider.py
```
**Use case:** Quick testing, debugging specific pages

---

### Workflow 2: Process annotated dataset
```bash
# 1. Process all pages
python decider_label_studio.py

# 2. Calculate metrics
python metrics.py
```
**Use case:** Evaluate model performance, generate results

---

### Workflow 3: Debug conversion/analysis
```bash
# 1. Test conversion
python conversion3.py

# 2. Test analysis
python check_markdown.py

# 3. Test collection
python collect.py
```
**Use case:** Debug pipeline components, verify output

---

### Workflow 4: Adjust thresholds
```bash
# 1. Edit table_decider.py â†’ MEANINGFUL_WORDS_THRESHOLD
# 2. Edit page_decider.py â†’ WORDS_OUTSIDE_TABLES_THRESHOLD
# 3. Re-run pipeline
python decider_label_studio.py
python metrics.py

# 4. Compare results
```
**Use case:** Optimize detection thresholds

---

## ğŸ“Š Module Dependencies

```
conversion3.py          (standalone - no dependencies)
        â”‚
        â–¼
check_markdown.py       (imports: conversion3)
        â”‚
        â–¼
collect.py             (imports: check_markdown)
        â”‚
        â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â–¼              â–¼              â–¼
table_decider.py   decider.py   decider_label_studio.py
        â”‚              â”‚              â”‚
        â–¼              â”‚              â”‚
page_decider.py â—„â”€â”€â”€â”€â”€â”€â”˜              â”‚
        â”‚                             â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â–¼
                 metrics.py
```

**Import hierarchy:**
1. `conversion3.py` - No dependencies
2. `check_markdown.py` - Uses `conversion3`
3. `collect.py` - Uses `check_markdown`
4. `table_decider.py` - Uses `collect`
5. `page_decider.py` - Uses `collect`, `table_decider`
6. `decider.py` - Uses `collect`, `page_decider`
7. `decider_label_studio.py` - Uses `collect`, `page_decider`
8. `metrics.py` - Standalone (uses sklearn)

---

## ğŸ“ Quick Reference

| Task | Command | Purpose |
|------|---------|---------|
| Test conversion | `python conversion3.py` | Verify HTML â†’ Markdown |
| Analyze page | `python check_markdown.py` | Extract metrics |
| Collect data | `python collect.py` | Test aggregation |
| Check table | `python table_decider.py` | Test table logic |
| Check page | `python page_decider.py [index]` | Test page logic |
| Test specific | `python decider.py` | Test by ID/URL |
| Process batch | `python decider_label_studio.py` | Run on dataset |
| Calculate metrics | `python metrics.py` | Evaluate performance |

---

## ğŸ¯ Key Features

- âœ… **Modular Design** - Independent components
- âœ… **Easy Configuration** - All parameters at top
- âœ… **Standalone Testing** - Each module runs independently
- âœ… **Async Processing** - Fast batch operations
- âœ… **Clear Output** - Well-formatted results
- âœ… **Comprehensive Metrics** - Full evaluation suite

---

## ğŸ”— Related Documentation

- **[Data Guide](../../DATA_README.md)** - Complete data documentation
- **[Label Studio](../label_studio/README.md)** - Annotation workflow

---

**Last Updated:** January 7, 2025
